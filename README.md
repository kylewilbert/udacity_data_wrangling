# udacity_data_wrangling
Data Wrangling Project in Python completed for Udacity Data Analysis Nanodegree

## Overview of Project
For this Udacity project, we were asked to wrangle data about the Twitter account WeRateDogs
(@dog_rates).

- The first dataset was an archive of tweets from WeRateDogs, presented to us as a CSV.
- The second was a TSV of image predictions results that we downloaded programmatically. The
project creator passed the photos from the tweets into a machine learning project and it spit
out these predictions.
- And the third source we scraped from Twitter using the Tweepy Python library.
- After wrangling and cleaning the data, I was left with 1992 tweets (no retweets).

### Methods Used
- web scraping/API
- data assessment
- data cleaning/processing
- descriptive statistics
- data visualization

### Technologies Used
- Python
    - Pandas
    - Numpy
    - Tweepy
    - Requests
    - JSON
### Contents
- act_report.pdf - insights and results from wrangling and analysis
- image-predictions.tsv - prediction results, provided by Udacity, downloaded programmatically
- tweet_json.txt - text file of tweets, scraped using Twitter API and Tweepy (code within wrangle_act.ipynb) 
- twitter_archive_master.csv - cleaned dataset
- twitter-archive-enhanced.csv - dataset provided by Udacity
- wrangle_act.ipynb - Jupyter notebook containing wrangling and analysis (basic structure provided by Udacity) 
- wrangle_report.pdf - notes about wrangling process and reflection on project results
